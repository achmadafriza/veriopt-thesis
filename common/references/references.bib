@unpublished{CompilerOptimization,
	title        = {Future Directions for Optimizing Compilers},
	author       = {Nuno P. Lopes and John Regehr},
	year         = 2018,
	month        = sep,
	note         = {arXiv preprint},
	eprint       = {1809.02161},
	archiveprefix = {arXiv},
	primaryclass = {cs.PL},
	abstract     = {
		As software becomes larger, programming languages become higher-level, and
		processors continue to fail to be clocked faster, we'll increasingly require
		compilers to reduce code bloat, eliminate abstraction penalties, and exploit
		interesting instruction sets. At the same time, compiler execution time must
		not increase too much and also compilers should never produce the wrong
		output. This paper examines the problem of making optimizing compilers
		faster, less buggy, and more capable of generating high-quality output.
	}
}

@article{testing,
	title = {An overview of regression testing},
	volume = {24},
	issn = {0163-5948},
	doi = {10.1145/308769.308790},
	abstract = {Regression testing is an important part of the software development life cycle. Many articles have been published lately detailing the different approaches. This article is an overview of regression testing in the following areas: types of regression testing; unit, integration and system level testing, regression testing of global variables, regression testing of object-oriented software, comparisons of selective regression techniques, and cost comparisons of the types of regression testing.},
	number = {1},
	journal = {ACM SIGSOFT Software Engineering Notes},
	author = {Wahl, Nancy J.},
	month = jan,
	year = {1999},
	pages = {69--73},
	file = {Full Text PDF:C\:\\Users\\Achmad Afriza\\Zotero\\storage\\PPKZADYJ\\Wahl - 1999 - An overview of regression testing.pdf:application/pdf},
}

@article{differentialTesting,
	title = {Differential {Testing} for {Software}},
	volume = {10},
	number = {1},
	pages={100--107},
	author = {McKeeman, William M},
	year = {1998},
	file = {McKeeman - 1998 - Differential Testing for Software.pdf:C\:\\Users\\Achmad Afriza\\Zotero\\storage\\NHW2MZVL\\McKeeman - 1998 - Differential Testing for Software.pdf:application/pdf},
}

@inproceedings{randomTesting,
	address = {New York, NY, USA},
	series = {{PLDI} '11},
	title = {Finding and understanding bugs in {C} compilers},
	isbn = {978-1-4503-0663-8},
	doi = {10.1145/1993498.1993532},
	abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to find compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our first contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undefined and unspecified behaviors that would destroy its ability to automatically find wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
	booktitle = {Proceedings of the 32nd {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
	month = jun,
	year = {2011},
	keywords = {automated testing, compiler defect, compiler testing, random program generation, random testing},
	pages = {283--294},
	file = {Full Text PDF:C\:\\Users\\Achmad Afriza\\Zotero\\storage\\FMK5ESHF\\Yang et al. - 2011 - Finding and understanding bugs in C compilers.pdf:application/pdf},
}

@article{compcertVerification,
	title = {Formal verification of a realistic compiler},
	volume = {52},
	issn = {0001-0782, 1557-7317},
	doi = {10.1145/1538788.1538814},
	abstract = {This paper reports on the development and formal veriﬁcation (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a veriﬁed compiler is useful in the context of critical software and its formal veriﬁcation: the veriﬁcation of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
	number = {7},
	journal = {Communications of the ACM},
	author = {Leroy, Xavier},
	month = jul,
	year = {2009},
	pages = {107--115},
	file = {Leroy - 2009 - Formal verification of a realistic compiler.pdf:C\:\\Users\\Achmad Afriza\\Zotero\\storage\\9YIU2FJC\\Leroy - 2009 - Formal verification of a realistic compiler.pdf:application/pdf},
}

@misc{graal,
	title        = {{GraalVM}: Run Programs Faster Anywhere},
	author       = {Oracle},
	year         = 2020,
	url          = {https://github.com/oracle/graal},
	urldate = {2023-09-13},
}

@misc{llvm,
	title = {The {LLVM} {Compiler} {Infrastructure} {Project}},
	url = {https://llvm.org/},
	urldate = {2023-08-20},
	file = {The LLVM Compiler Infrastructure Project:C\:\\Users\\Achmad Afriza\\Zotero\\storage\\AJCYBM5G\\llvm.org.html:text/html},
}

@inproceedings{AliveInLean,
	title        = {{AliveInLean}: A Verified {LLVM} Peephole Optimization Verifier},
	author       = {Lee, Juneyoung and Hur, Chung-Kil and Lopes, Nuno P.},
	year         = 2019,
	booktitle    = {Computer Aided Verification},
	pages        = {445-455},
	doi          = {10.1007/978-3-030-25543-5_25},
	isbn         = {978-3-030-25543-5},
	editor       = {Dillig, Isil and Tasiran, Serdar},
	abstract     = {
		Ensuring that compiler optimizations are correct is important for the
		reliability of the entire software ecosystem, since all software is compiled.
		Alive [12] is a tool for verifying LLVM's peephole optimizations. Since Alive
		was released, it has helped compiler developers proactively find dozens of
		bugs in LLVM, avoiding potentially hazardous miscompilations. Despite having
		verified many LLVM optimizations so far, Alive is itself not verified, which
		has led to at least once declaring an optimization correct when it was not.
	},
	annotate     = {
		Presents an optimization verifier for LLVM written in Lean. Improving on the
		prior work of Alive which relies on the trusted code base of the LLVM
		semantics, verification condition generation, and the SMT solver. This paper
		addresses the trusted semantics of LLVM via randomly generated IR programs.
		The trust of the SMT solver is addressed by comparing the SMT expressions
		with equivalent expressions in Lean. The implementation is limited to integer
		transformations ignoring procedure calls.
	}
}

@inproceedings{Alive2,
	address = {Virtual Canada},
	title = {Alive2: bounded translation validation for {LLVM}},
	isbn = {978-1-4503-8391-2},
	shorttitle = {Alive2},
	doi = {10.1145/3453483.3454030},
	abstract = {We designed, implemented, and deployed Alive2: a bounded translation validation tool for the LLVM compiler’s intermediate representation (IR). It limits resource consumption by, for example, unrolling loops up to some bound, which means there are circumstances in which it misses bugs. Alive2 is designed to avoid false alarms, is fully automatic through the use of an SMT solver, and requires no changes to LLVM. By running Alive2 over LLVM’s unit test suite, we discovered and reported 47 new bugs, 28 of which have been fixed already. Moreover, our work has led to eight patches to the LLVM Language Reference—the definitive description of the semantics of its IR—and we have participated in numerous discussions with the goal of clarifying ambiguities and fixing errors in these semantics. Alive2 is open source and we also made it available on the web, where it has active users from the LLVM community.},
	booktitle = {Proceedings of the 42nd {ACM} {SIGPLAN} {International} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Lopes, Nuno P. and Lee, Juneyoung and Hur, Chung-Kil and Liu, Zhengyang and Regehr, John},
	month = jun,
	year = {2021},
	pages = {65--79},
	file = {Lopes et al. - 2021 - Alive2 bounded translation validation for LLVM.pdf:C\:\\Users\\Achmad Afriza\\Zotero\\storage\\R263V8IH\\Lopes et al. - 2021 - Alive2 bounded translation validation for LLVM.pdf:application/pdf},
}

@misc{kobschatzki_unexpected_2024,
	title = {Unexpected {Behavior} with {Isabelle} {Server} 2023},
	url = {https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2024-01/msg00006.html},
	urldate = {2024-05-06},
	author = {Kobschätzki, Joshua},
	month = jan,
	year = {2024},
	file = {cl-isabelle-users - [isabelle] Unexpected Behavior with Isabelle Server 2023 - arc:C\:\\Users\\Afriza\\Zotero\\storage\\WASZHGAF\\msg00006.html:text/html},
}

@misc{huch_isabelle_2022,
	title = {The {Isabelle} {Community} {Benchmark}},
	url = {http://arxiv.org/abs/2209.13894},
	doi = {10.48550/arXiv.2209.13894},
	abstract = {Choosing hardware for theorem proving is no simple task: automated provers are highly complex and optimized programs, often utilizing a parallel computation model, and there is little prior research on the hardware impact on prover performance. To alleviate the problem for Isabelle, we initiated a community benchmark where the build time of HOL-Analysis is measured. On \$54\$ distinct CPUs, a total of \$669\$ runs with different Isabelle configurations were reported by Isabelle users. Results range from \$107\$s to over \$11\$h. We found that current consumer CPUs performed best, with an optimal number of \$8\$ to \$16\$ threads, largely independent of heap memory. As for hardware parameters, CPU base clock affected multi-threaded execution most with a linear correlation of \$0.37\$, whereas boost frequency was the most influential parameter for single-threaded runs (correlation coefficient \$0.55\$); cache size played no significant role. When comparing our benchmark scores with popular high-performance computing benchmarks, we found a strong linear relationship with Dolfyn (\$R{\textasciicircum}2 = 0.79\$) in the single-threaded scenario. Using data from the 3DMark CPU Profile consumer benchmark, we created a linear model for optimal (multi-threaded) Isabelle performance. When validating, the model has an average \$R{\textasciicircum}2\$-score of \$0.87\$; the mean absolute error in the final model corresponds to a wall-clock time of \$46.6\$s. With a dataset of true median values for the 3DMark, the error improves to \$37.1\$s.},
	urldate = {2024-05-29},
	publisher = {arXiv},
	author = {Huch, Fabian and Bode, Vincent},
	month = sep,
	year = {2022},
	note = {arXiv:2209.13894 [cs]},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:C\:\\Users\\Afriza\\Zotero\\storage\\7RWQXAFI\\Huch and Bode - 2022 - The Isabelle Community Benchmark.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Afriza\\Zotero\\storage\\9Q8MA6C2\\2209.html:text/html},
}

@book{dahl_structured_1972,
	address = {GBR},
	title = {Structured programming},
	isbn = {978-0-12-200550-3},
	abstract = {In recent years there has been an increasing interest in the art of computer programming, the conceptual tools available for the design of programs, and the prevention of programming oversights and error. The initial outstanding contribution to our understanding of this subject was made by E. W. Dijkstra, whose Notes on Structured Programming form the first and major section of this book. They clearly expound the reflections of a brilliant programmer on the methods which he has hitherto unconsciously applied; there can be no programmer of the present day who could not increase his skills by a study and conscious application of these principles. In the second monograph I have tried to describe how similar principles can be applied in the design of data structures. I have suggested that in analysing a problem and groping towards a solution, a programmer should take advantage of abstract concepts such as sets, sequences, and mappings; and judiciously postpone decisions on representation until he is constructing the more detailed code of the program. The monograph also describes a range of useful ideas for data representation, and suggests the criteria relevant for their selection. The third monograph provides a synthesis of the previous two, and expounds the close theoretical and practical connections between the design of data and the design of programs. It introduces useful additional methods for program and data structuring which may be unfamiliar to many programmers. The examples show that structured programming principles can be equally applied in "bottom-up" as in "top-down" program design. The original inspiration, insight, and all the examples were contributed by O.-J. Dahl; I have only assembled the material, and added some additional explanations where I found it difficult to understand.},
	publisher = {Academic Press Ltd.},
	editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
	year = {1972},
	file = {Full Text PDF:C\:\\Users\\Afriza\\Zotero\\storage\\C394EXVM\\Dahl et al. - 1972 - Structured programming.pdf:application/pdf},
}

@inproceedings{offutt_mutation_2006,
	address = {Raleigh, NC, USA},
	title = {Mutation {Testing} implements {Grammar}-{Based} {Testing}},
	isbn = {978-0-7695-2897-7},
	url = {http://ieeexplore.ieee.org/document/4144731/},
	doi = {10.1109/MUTATION.2006.11},
	abstract = {This paper presents an abstract view of mutation analysis. Mutation was originally thought of as making changes to program source, but similar kinds of changes have been applied to other artifacts, including program speciﬁcations, XML, and input languages. This paper argues that mutation analysis is actually a way to modify any software artifact based on its syntactic description, and is in the same family of test generation methods that create inputs from syntactic descriptions. The essential characteristic of mutation is that a syntactic description such as a grammar is used to create tests. We call this abstract view grammar-based testing, and view it as an interface, which mutation analysis implements. This shift in view allows mutation to be deﬁned in a general way, yielding three beneﬁts. First, it provides a simpler way to understand mutation. Second, it makes it easier to develop future applications of mutation analysis, such as ﬁnite state machines and use case collaboration diagrams. The third beneﬁt, which due to space limitations is not explored in this paper, is ensuring that existing techniques are complete according to the criteria deﬁned here.},
	language = {en},
	urldate = {2024-05-25},
	booktitle = {Second {Workshop} on {Mutation} {Analysis} ({Mutation} 2006 - {ISSRE} {Workshops} 2006)},
	publisher = {IEEE},
	author = {Offutt, Jeff and Ammann, Paul and Liu, Lisa},
	month = nov,
	year = {2006},
	pages = {12--12},
	file = {Offutt et al. - 2006 - Mutation Testing implements Grammar-Based Testing.pdf:C\:\\Users\\Afriza\\Zotero\\storage\\DAWGNAMC\\Offutt et al. - 2006 - Mutation Testing implements Grammar-Based Testing.pdf:application/pdf},
}

@misc{fasterxml_objectmapper_nodate,
	title = {{ObjectMapper} (jackson-databind 2.7.0 {API})},
	url = {https://fasterxml.github.io/jackson-databind/javadoc/2.7/com/fasterxml/jackson/databind/ObjectMapper.html},
	urldate = {2024-05-28},
	author = {{FasterXML}},
	file = {ObjectMapper (jackson-databind 2.7.0 API):C\:\\Users\\Afriza\\Zotero\\storage\\RE5KBXDG\\ObjectMapper.html:text/html},
}

@misc{docker_inc_docker_2022,
	title = {Docker: {Accelerated} {Container} {Application} {Development}},
	shorttitle = {Docker},
	url = {https://www.docker.com/},
	abstract = {Docker is a platform designed to help developers build, share, and run container applications. We handle the tedious setup, so you can focus on the code.},
	language = {en-US},
	urldate = {2024-05-28},
	author = {{Docker Inc.}},
	month = may,
	year = {2022},
	file = {Snapshot:C\:\\Users\\Afriza\\Zotero\\storage\\KKRGPGD9\\www.docker.com.html:text/html},
}
